{
  "model_size": "base",
  "learning_rate": 1e-5,
  "generator_hidden_size": 0.333,
  "vocab_size": 32200,
  "do_lower_case": false,
  "train_batch_size": 16,
  "eval_batch_size": 32,
  "num_train_steps": 1000000,
  "save_checkpoints_steps": 1000,
  "num_eval_steps": 1000,
  "max_seq_length": 512,
  "model_hparam_overrides": {
    "max_position_embeddings": 512
  }
}
